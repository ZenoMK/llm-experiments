[2025-03-11 01:46:10,126][INFO] step 0: train loss 4.6466, val loss 4.6462
[2025-03-11 01:46:13,420][INFO] iter 0: loss 4.6477
[2025-03-11 01:46:18,202][INFO] iter 100: loss 3.9767
[2025-03-11 01:46:23,213][INFO] iter 200: loss 3.1286
[2025-03-11 01:46:27,898][INFO] iter 300: loss 2.5012
[2025-03-11 01:46:32,603][INFO] iter 400: loss 2.1962
[2025-03-11 01:46:37,878][INFO] iter 500: loss 2.0821
[2025-03-11 01:46:42,777][INFO] iter 600: loss 2.0265
[2025-03-11 01:46:47,853][INFO] iter 700: loss 2.0046
[2025-03-11 01:46:52,624][INFO] iter 800: loss 1.9838
[2025-03-11 01:46:57,836][INFO] iter 900: loss 1.9702
[2025-03-11 01:48:02,747][INFO] step 1000: train loss 1.9635, val loss 1.9623
[2025-03-11 01:48:02,748][INFO] saving checkpoint to out/markov_chain_1_1_120_100_path
[2025-03-11 01:48:02,854][INFO] iter 1000: loss 1.9678
[2025-03-11 01:48:07,695][INFO] iter 1100: loss 1.9519
[2025-03-11 01:48:12,701][INFO] iter 1200: loss 1.9378
[2025-03-11 01:48:17,468][INFO] iter 1300: loss 1.9270
[2025-03-11 01:48:22,254][INFO] iter 1400: loss 1.9267
[2025-03-11 01:48:27,327][INFO] iter 1500: loss 1.9119
[2025-03-11 01:48:32,230][INFO] iter 1600: loss 1.8967
[2025-03-11 01:48:37,224][INFO] iter 1700: loss 1.8875
[2025-03-11 01:48:41,979][INFO] iter 1800: loss 1.8830
[2025-03-11 01:48:46,755][INFO] iter 1900: loss 1.8743
[2025-03-11 01:49:51,486][INFO] step 2000: train loss 1.8597, val loss 1.8601
[2025-03-11 01:49:51,487][INFO] saving checkpoint to out/markov_chain_1_1_120_100_path
[2025-03-11 01:49:51,593][INFO] iter 2000: loss 1.8619
[2025-03-11 01:49:56,363][INFO] iter 2100: loss 1.8551
[2025-03-11 01:50:01,312][INFO] iter 2200: loss 1.8446
[2025-03-11 01:50:06,053][INFO] iter 2300: loss 1.8297
[2025-03-11 01:50:11,429][INFO] iter 2400: loss 1.8154
[2025-03-11 01:50:16,315][INFO] iter 2500: loss 1.8065
